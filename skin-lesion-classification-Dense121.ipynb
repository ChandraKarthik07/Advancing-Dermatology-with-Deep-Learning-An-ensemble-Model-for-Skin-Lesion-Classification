{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" ### First, import all libraries","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\n# python libraties\nimport os, cv2,itertools\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom glob import glob\nfrom PIL import Image\n\n# pytorch libraries\nimport torch\nfrom torch import optim,nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader,Dataset\nfrom torchvision import models,transforms\n\n# sklearn libraries\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\n# to make the results are reproducible\nnp.random.seed(10)\ntorch.manual_seed(10)\ntorch.cuda.manual_seed(10)\n\nprint(os.listdir(\"../input\"))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-18T08:17:13.432974Z","iopub.execute_input":"2024-02-18T08:17:13.433425Z","iopub.status.idle":"2024-02-18T08:17:13.449178Z","shell.execute_reply.started":"2024-02-18T08:17:13.433395Z","shell.execute_reply":"2024-02-18T08:17:13.448262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 1. Data analysis and preprocessing","metadata":{}},{"cell_type":"markdown","source":"Get the all image data pathsï¼Œ match the row information in HAM10000_metadata.csv with its corresponding image","metadata":{}},{"cell_type":"code","source":"data_dir = '../input'\nall_image_path = glob(os.path.join(data_dir, '*', '*.jpg'))\nimageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in all_image_path}\nlesion_type_dict = {\n    'nv': 'Melanocytic nevi',\n    'mel': 'dermatofibroma',\n    'bkl': 'Benign keratosis-like lesions ',\n    'bcc': 'Basal cell carcinoma',\n    'akiec': 'Actinic keratoses',\n    'vasc': 'Vascular lesions',\n    'df': 'Dermatofibroma'\n}","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2024-02-18T08:17:13.451144Z","iopub.execute_input":"2024-02-18T08:17:13.451595Z","iopub.status.idle":"2024-02-18T08:17:13.595831Z","shell.execute_reply.started":"2024-02-18T08:17:13.451552Z","shell.execute_reply":"2024-02-18T08:17:13.595049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This function is used to compute the mean and standard deviation on the whole dataset, will use for inputs normalization","metadata":{}},{"cell_type":"code","source":"def compute_img_mean_std(image_paths):\n    img_h, img_w = 224, 224\n    imgs = []\n    means, stdevs = [], []\n\n    for i in tqdm(range(len(image_paths))):\n        img = cv2.imread(image_paths[i])\n        img = cv2.resize(img, (img_h, img_w))\n        imgs.append(img)\n\n    imgs = np.stack(imgs, axis=3)\n    print(imgs.shape)\n\n    imgs = imgs.astype(np.float32) / 255.\n\n    for i in range(3):\n        pixels = imgs[:, :, i, :].ravel()  # resize to one row\n        means.append(np.mean(pixels))\n        stdevs.append(np.std(pixels))\n\n    means.reverse()  # BGR --> RGB\n    stdevs.reverse()\n\n    print(\"normMean = {}\".format(means))\n    print(\"normStd = {}\".format(stdevs))\n    return means,stdevs","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:17:13.596876Z","iopub.execute_input":"2024-02-18T08:17:13.597155Z","iopub.status.idle":"2024-02-18T08:17:13.607600Z","shell.execute_reply.started":"2024-02-18T08:17:13.597132Z","shell.execute_reply":"2024-02-18T08:17:13.606711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Return the mean and std of RGB channels","metadata":{}},{"cell_type":"code","source":"norm_mean,norm_std = compute_img_mean_std(all_image_path)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:17:13.608569Z","iopub.execute_input":"2024-02-18T08:17:13.608801Z","iopub.status.idle":"2024-02-18T08:21:40.144421Z","shell.execute_reply.started":"2024-02-18T08:17:13.608780Z","shell.execute_reply":"2024-02-18T08:21:40.143475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Add three columns to the original DataFrame, path (image path), cell_type (the whole name),cell_type_idx (the corresponding index  of cell type, as the image label )","metadata":{}},{"cell_type":"code","source":"df_original = pd.read_csv(os.path.join(data_dir, 'HAM10000_metadata.csv'))\ndf_original['path'] = df_original['image_id'].map(imageid_path_dict.get)\ndf_original['cell_type'] = df_original['dx'].map(lesion_type_dict.get)\ndf_original['cell_type_idx'] = pd.Categorical(df_original['cell_type']).codes\ndf_original.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:21:40.147053Z","iopub.execute_input":"2024-02-18T08:21:40.147369Z","iopub.status.idle":"2024-02-18T08:21:40.188685Z","shell.execute_reply.started":"2024-02-18T08:21:40.147345Z","shell.execute_reply":"2024-02-18T08:21:40.187804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Images associated with each lesion_id and filtering them","metadata":{}},{"cell_type":"code","source":"df_undup = df_original.groupby('lesion_id').count()\ndf_undup = df_undup[df_undup['image_id'] == 1]\ndf_undup.reset_index(inplace=True)\ndf_undup.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:21:40.189825Z","iopub.execute_input":"2024-02-18T08:21:40.190126Z","iopub.status.idle":"2024-02-18T08:21:40.233140Z","shell.execute_reply.started":"2024-02-18T08:21:40.190101Z","shell.execute_reply":"2024-02-18T08:21:40.232142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Identifying lesion_id's that have duplicate images and those that have only one image.","metadata":{}},{"cell_type":"code","source":"def get_duplicates(x):\n    unique_list = list(df_undup['lesion_id'])\n    if x in unique_list:\n        return 'unduplicated'\n    else:\n        return 'duplicated'\n\n# create a new colum that is a copy of the lesion_id column\ndf_original['duplicates'] = df_original['lesion_id']\n# apply the function to this new column\ndf_original['duplicates'] = df_original['duplicates'].apply(get_duplicates)\ndf_original.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:21:40.234375Z","iopub.execute_input":"2024-02-18T08:21:40.234772Z","iopub.status.idle":"2024-02-18T08:21:47.407149Z","shell.execute_reply.started":"2024-02-18T08:21:40.234744Z","shell.execute_reply":"2024-02-18T08:21:47.406044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_original['duplicates'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:21:47.408710Z","iopub.execute_input":"2024-02-18T08:21:47.409101Z","iopub.status.idle":"2024-02-18T08:21:47.418391Z","shell.execute_reply.started":"2024-02-18T08:21:47.409058Z","shell.execute_reply":"2024-02-18T08:21:47.417476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### filter out images that don't have duplicates","metadata":{}},{"cell_type":"code","source":"df_undup = df_original[df_original['duplicates'] == 'unduplicated']\ndf_undup.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:21:47.419898Z","iopub.execute_input":"2024-02-18T08:21:47.420351Z","iopub.status.idle":"2024-02-18T08:21:47.431933Z","shell.execute_reply.started":"2024-02-18T08:21:47.420317Z","shell.execute_reply":"2024-02-18T08:21:47.430961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now we create a val set using df because we are sure that none of these images have augmented duplicates in the train set\ny = df_undup['cell_type_idx']\n_, df_val = train_test_split(df_undup, test_size=0.2, random_state=101, stratify=y)\ndf_val.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:21:47.433139Z","iopub.execute_input":"2024-02-18T08:21:47.433458Z","iopub.status.idle":"2024-02-18T08:21:47.447592Z","shell.execute_reply.started":"2024-02-18T08:21:47.433427Z","shell.execute_reply":"2024-02-18T08:21:47.446631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val['cell_type_idx'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:21:47.448818Z","iopub.execute_input":"2024-02-18T08:21:47.449113Z","iopub.status.idle":"2024-02-18T08:21:47.456395Z","shell.execute_reply.started":"2024-02-18T08:21:47.449087Z","shell.execute_reply":"2024-02-18T08:21:47.455427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This set will be df_original excluding all rows that are in the val set\n# This function identifies if an image is part of the train or val set.\ndef get_val_rows(x):\n    val_list = list(df_val['image_id'])\n    if str(x) in val_list:\n        return 'val'\n    else:\n        return 'train'\n\n# identify train and val rows\n# create a new colum that is a copy of the image_id column\ndf_original['train_or_val'] = df_original['image_id']\n# apply the function to this new column\ndf_original['train_or_val'] = df_original['train_or_val'].apply(get_val_rows)\n# filter out train rows\ndf_train = df_original[df_original['train_or_val'] == 'train']\nprint(len(df_train))\nprint(len(df_val))","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:21:47.457546Z","iopub.execute_input":"2024-02-18T08:21:47.457843Z","iopub.status.idle":"2024-02-18T08:21:49.110137Z","shell.execute_reply.started":"2024-02-18T08:21:47.457819Z","shell.execute_reply":"2024-02-18T08:21:49.109131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['cell_type_idx'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:21:49.111321Z","iopub.execute_input":"2024-02-18T08:21:49.111576Z","iopub.status.idle":"2024-02-18T08:21:49.119256Z","shell.execute_reply.started":"2024-02-18T08:21:49.111555Z","shell.execute_reply":"2024-02-18T08:21:49.118243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val['cell_type'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:21:49.123763Z","iopub.execute_input":"2024-02-18T08:21:49.124030Z","iopub.status.idle":"2024-02-18T08:21:49.132178Z","shell.execute_reply.started":"2024-02-18T08:21:49.124007Z","shell.execute_reply":"2024-02-18T08:21:49.131259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As we can see from the statistics of each category above, the training data has a significant class imbalance. I believe there are two places we can start when solving this issue: equalization sampling and loss functions like focused loss that can be utilized to reduce category imbalance during training.**","metadata":{}},{"cell_type":"code","source":"# Assuming df_train is a pandas DataFrame\ndata_aug_rate = [15, 10, 5, 50, 0, 40, 5]\nfor i in range(7):\n    if data_aug_rate[i]:\n        subset_df = df_train[df_train['cell_type_idx'] == i]\n        df_train = pd.concat([df_train, pd.concat([subset_df] * (data_aug_rate[i] - 1))],\n                            ignore_index=True)\n\ndf_train['cell_type'].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:21:49.133282Z","iopub.execute_input":"2024-02-18T08:21:49.133625Z","iopub.status.idle":"2024-02-18T08:21:49.181114Z","shell.execute_reply.started":"2024-02-18T08:21:49.133591Z","shell.execute_reply":"2024-02-18T08:21:49.180142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"At the beginning, I divided the data into three parts, training set, validation set and test set. Considering the small amount of data, I did not further divide the validation set data in practice.","metadata":{}},{"cell_type":"code","source":"df_train = df_train.reset_index()\ndf_val = df_val.reset_index()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:21:49.182518Z","iopub.execute_input":"2024-02-18T08:21:49.183191Z","iopub.status.idle":"2024-02-18T08:21:49.198580Z","shell.execute_reply.started":"2024-02-18T08:21:49.183158Z","shell.execute_reply":"2024-02-18T08:21:49.197768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 2. Model building","metadata":{}},{"cell_type":"code","source":"def set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        for param in model.parameters():\n            param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:21:49.199647Z","iopub.execute_input":"2024-02-18T08:21:49.199973Z","iopub.status.idle":"2024-02-18T08:21:49.205220Z","shell.execute_reply.started":"2024-02-18T08:21:49.199947Z","shell.execute_reply":"2024-02-18T08:21:49.204250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n    model_ft = None\n    input_size = 0\n\n    if model_name == \"densenet\":\n        model_ft = models.densenet121(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier.in_features\n        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n\n    else:\n        print(\"Invalid model name, exiting...\")\n        exit()\n    return model_ft, input_size","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:21:49.206476Z","iopub.execute_input":"2024-02-18T08:21:49.206795Z","iopub.status.idle":"2024-02-18T08:21:49.217349Z","shell.execute_reply.started":"2024-02-18T08:21:49.206763Z","shell.execute_reply":"2024-02-18T08:21:49.216606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# resnet,vgg,densenet\nmodel_name = 'densenet'\nnum_classes = 7\nfeature_extract = False\n# Initialize the model for this run\nmodel_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n# Define the device:\ndevice = torch.device('cuda:0')\n# Put the model on the device:\nmodel = model_ft.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:21:49.218694Z","iopub.execute_input":"2024-02-18T08:21:49.219029Z","iopub.status.idle":"2024-02-18T08:21:50.250343Z","shell.execute_reply.started":"2024-02-18T08:21:49.218998Z","shell.execute_reply":"2024-02-18T08:21:50.249458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the transformation of the train images.\ntrain_transform = transforms.Compose([transforms.Resize((input_size,input_size)),transforms.RandomHorizontalFlip(),\n                                      transforms.RandomVerticalFlip(),transforms.RandomRotation(20),\n                                      transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n                                        transforms.ToTensor(), transforms.Normalize(norm_mean, norm_std)])\n# define the transformation of the val images.\nval_transform = transforms.Compose([transforms.Resize((input_size,input_size)), transforms.ToTensor(),\n                                    transforms.Normalize(norm_mean, norm_std)])","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:21:50.251893Z","iopub.execute_input":"2024-02-18T08:21:50.252282Z","iopub.status.idle":"2024-02-18T08:21:50.259340Z","shell.execute_reply.started":"2024-02-18T08:21:50.252249Z","shell.execute_reply":"2024-02-18T08:21:50.258354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define a pytorch dataloader for this dataset","metadata":{}},{"cell_type":"code","source":"\nclass HAM10000(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        # Load data and get label\n        X = Image.open(self.df['path'][index])\n        y = torch.tensor(int(self.df['cell_type_idx'][index]))\n\n        if self.transform:\n            X = self.transform(X)\n\n        return X, y","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:21:50.260656Z","iopub.execute_input":"2024-02-18T08:21:50.260995Z","iopub.status.idle":"2024-02-18T08:21:50.269922Z","shell.execute_reply.started":"2024-02-18T08:21:50.260963Z","shell.execute_reply":"2024-02-18T08:21:50.268900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define the training set and validation set using the table train_df and using our defined transitions (train_transform)","metadata":{}},{"cell_type":"code","source":"\ntraining_set = HAM10000(df_train, transform=train_transform)\ntrain_loader = DataLoader(training_set, batch_size=32, shuffle=True, num_workers=4)\n\nvalidation_set = HAM10000(df_val, transform=train_transform)\nval_loader = DataLoader(validation_set, batch_size=32, shuffle=False, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:21:50.271194Z","iopub.execute_input":"2024-02-18T08:21:50.271633Z","iopub.status.idle":"2024-02-18T08:21:50.280426Z","shell.execute_reply.started":"2024-02-18T08:21:50.271606Z","shell.execute_reply":"2024-02-18T08:21:50.279586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adam optimizer, use cross entropy loss as our loss function","metadata":{}},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss().to(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:21:50.281612Z","iopub.execute_input":"2024-02-18T08:21:50.281939Z","iopub.status.idle":"2024-02-18T08:21:50.294916Z","shell.execute_reply.started":"2024-02-18T08:21:50.281913Z","shell.execute_reply":"2024-02-18T08:21:50.294109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 3. Model training","metadata":{}},{"cell_type":"markdown","source":"This function is used during training process, to calculation the loss and accuracy","metadata":{}},{"cell_type":"code","source":"class AverageMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:21:50.296304Z","iopub.execute_input":"2024-02-18T08:21:50.296896Z","iopub.status.idle":"2024-02-18T08:21:50.304260Z","shell.execute_reply.started":"2024-02-18T08:21:50.296863Z","shell.execute_reply":"2024-02-18T08:21:50.303434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_loss_train, total_acc_train = [],[]\ndef train(train_loader, model, criterion, optimizer, epoch):\n    model.train()\n    train_loss = AverageMeter()\n    train_acc = AverageMeter()\n    curr_iter = (epoch - 1) * len(train_loader)\n    for i, data in enumerate(train_loader):\n        images, labels = data\n        N = images.size(0)\n        # print('image shape:',images.size(0), 'label shape',labels.size(0))\n        images = Variable(images).to(device)\n        labels = Variable(labels).to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        prediction = outputs.max(1, keepdim=True)[1]\n        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n        train_loss.update(loss.item())\n        curr_iter += 1\n        if (i + 1) % 100 == 0:\n            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n                epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n            total_loss_train.append(train_loss.avg)\n            total_acc_train.append(train_acc.avg)\n    return train_loss.avg, train_acc.avg","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:21:50.305267Z","iopub.execute_input":"2024-02-18T08:21:50.305549Z","iopub.status.idle":"2024-02-18T08:21:50.316941Z","shell.execute_reply.started":"2024-02-18T08:21:50.305526Z","shell.execute_reply":"2024-02-18T08:21:50.316144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate(val_loader, model, criterion, optimizer, epoch):\n    model.eval()\n    val_loss = AverageMeter()\n    val_acc = AverageMeter()\n    with torch.no_grad():\n        for i, data in enumerate(val_loader):\n            images, labels = data\n            N = images.size(0)\n            images = Variable(images).to(device)\n            labels = Variable(labels).to(device)\n\n            outputs = model(images)\n            prediction = outputs.max(1, keepdim=True)[1]\n\n            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n\n            val_loss.update(criterion(outputs, labels).item())\n\n    print('------------------------------------------------------------')\n    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n    print('------------------------------------------------------------')\n    return val_loss.avg, val_acc.avg","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:21:50.318037Z","iopub.execute_input":"2024-02-18T08:21:50.318330Z","iopub.status.idle":"2024-02-18T08:21:50.329743Z","shell.execute_reply.started":"2024-02-18T08:21:50.318308Z","shell.execute_reply":"2024-02-18T08:21:50.328973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epoch_num = 10\nbest_val_acc = 0\ntotal_loss_val, total_acc_val = [],[]\nfor epoch in range(1, epoch_num+1):\n    loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch)\n    loss_val, acc_val = validate(val_loader, model, criterion, optimizer, epoch)\n    total_loss_val.append(loss_val)\n    total_acc_val.append(acc_val)\n    if acc_val > best_val_acc:\n        best_val_acc = acc_val\n        print('*****************************************************')\n        print('best record: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n        print('*****************************************************')","metadata":{"execution":{"iopub.status.busy":"2024-02-18T08:21:50.330926Z","iopub.execute_input":"2024-02-18T08:21:50.331193Z","iopub.status.idle":"2024-02-18T09:03:53.702943Z","shell.execute_reply.started":"2024-02-18T08:21:50.331171Z","shell.execute_reply":"2024-02-18T09:03:53.701760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 4. Model evaluation","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(num = 2)\nfig1 = fig.add_subplot(2,1,1)\nfig2 = fig.add_subplot(2,1,2)\nfig1.plot(total_loss_train, label = 'training loss')\nfig1.plot(total_acc_train, label = 'training accuracy')\nfig2.plot(total_loss_val, label = 'validation loss')\nfig2.plot(total_acc_val, label = 'validation accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:03:53.704513Z","iopub.execute_input":"2024-02-18T09:03:53.704868Z","iopub.status.idle":"2024-02-18T09:03:54.046273Z","shell.execute_reply.started":"2024-02-18T09:03:53.704837Z","shell.execute_reply":"2024-02-18T09:03:54.045274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This function is used during training process, to calculation the loss and accuracy","metadata":{}},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:03:54.047485Z","iopub.execute_input":"2024-02-18T09:03:54.047765Z","iopub.status.idle":"2024-02-18T09:03:54.056667Z","shell.execute_reply.started":"2024-02-18T09:03:54.047742Z","shell.execute_reply":"2024-02-18T09:03:54.055553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\ny_label = []\ny_predict = []\nwith torch.no_grad():\n    for i, data in enumerate(val_loader):\n        images, labels = data\n        N = images.size(0)\n        images = Variable(images).to(device)\n        outputs = model(images)\n        prediction = outputs.max(1, keepdim=True)[1]\n        y_label.extend(labels.cpu().numpy())\n        y_predict.extend(np.squeeze(prediction.cpu().numpy().T))\n\n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(y_label, y_predict)\n# plot the confusion matrix\nplot_labels = ['akiec', 'bcc', 'bkl', 'df', 'nv', 'vasc','mel']\nplot_confusion_matrix(confusion_mtx, plot_labels)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:03:54.058055Z","iopub.execute_input":"2024-02-18T09:03:54.058337Z","iopub.status.idle":"2024-02-18T09:04:01.873574Z","shell.execute_reply.started":"2024-02-18T09:03:54.058315Z","shell.execute_reply":"2024-02-18T09:04:01.872501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generate a classification report","metadata":{}},{"cell_type":"code","source":"\nreport = classification_report(y_label, y_predict, target_names=plot_labels)\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:04:01.874976Z","iopub.execute_input":"2024-02-18T09:04:01.875301Z","iopub.status.idle":"2024-02-18T09:04:01.892479Z","shell.execute_reply.started":"2024-02-18T09:04:01.875270Z","shell.execute_reply":"2024-02-18T09:04:01.891334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_frac_error = 1 - np.diag(confusion_mtx) / np.sum(confusion_mtx, axis=1)\nplt.bar(np.arange(7),label_frac_error)\nplt.xlabel('True Label')\nplt.ylabel('Fraction classified incorrectly')","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:04:01.893802Z","iopub.execute_input":"2024-02-18T09:04:01.894466Z","iopub.status.idle":"2024-02-18T09:04:02.126063Z","shell.execute_reply.started":"2024-02-18T09:04:01.894433Z","shell.execute_reply":"2024-02-18T09:04:02.125035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_scripted = torch.jit.script(model) # Export to TorchScript\nmodel_scripted.save('densenet.pt') # Save","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:04:38.553295Z","iopub.execute_input":"2024-02-18T09:04:38.554233Z","iopub.status.idle":"2024-02-18T09:04:42.261956Z","shell.execute_reply.started":"2024-02-18T09:04:38.554175Z","shell.execute_reply":"2024-02-18T09:04:42.261078Z"},"trusted":true},"execution_count":null,"outputs":[]}]}